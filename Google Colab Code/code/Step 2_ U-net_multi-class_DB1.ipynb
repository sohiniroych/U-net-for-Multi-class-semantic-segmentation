{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Step 2: U-net_multi-class_DB1.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"n7yLKm_-kuii"},"source":["# This code implements segmentation of pathological regions from retinal images using a U-net model with depth 4 and tensorflow 2.x versions.\n","\n","## This code implements multi-class classification\n","## This model is adapted from the original codebase in https://github.com/HZCTony/U-net-with-multiple-classification"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RStzkXQwkuip","outputId":"3ace6ee3-8ac1-421e-e2a1-fee02d9f05b8"},"source":["# First lets connect the Gdrive that contains the data\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n","\n","Enter your authorization code:\n","4/1AY0e-g68gf7Dv8gUt9_ojyE0wuMV2zGvQ4XI_znIiJqAl9uwvIffqygT4vo\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c7xAEMCtlApo"},"source":["import os\n","# The path below should point to the directory containing this notebook and the associated utility files\n","# Change it if necessary\n","os.chdir('/content/drive/MyDrive/U-net Multi-class/code/')\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hsjiInH8kuiq"},"source":["# A. Lets start by stepwise defining all libraries and functions needed to generate the model and pre-process the data"]},{"cell_type":"code","metadata":{"id":"CKpTzQkOkuiq"},"source":["#Step 1: Load libraries for the U-net Model\n","import numpy as np \n","import os\n","import skimage.io as io\n","import skimage.transform as trans\n","import numpy as np\n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from tensorflow.keras import backend as keras\n","#from tensorflow import keras\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1AzDVayVkuiq"},"source":["#Step 2: Import the U-net model\n","from model_depth_4 import *\n","img_size=(512,512)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbKhpLx5kuir"},"source":["n_class=3\n","#Create Groundtruth with 5 planes:[Red Lesions(0), Bright Lesions(1), background (2) ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"apyaqeIDkuir"},"source":["#Step 3:Define functions for pre-processing data\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import skimage.io as io\n","import skimage.transform as trans\n","import matplotlib.pyplot as plt\n","import scipy.misc as sc\n","\n","\n","def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n","                    mask_color_mode = \"rgb\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n","                    flag_multi_class = True,n_class = n_class,save_to_dir = None,target_size = img_size,seed = 1):\n","    '''\n","    can generate image and mask at the same time\n","    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n","    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n","    '''\n","    image_datagen = ImageDataGenerator(**aug_dict)\n","    mask_datagen = ImageDataGenerator(**aug_dict)\n","    image_generator = image_datagen.flow_from_directory(\n","        train_path,\n","        classes = [image_folder],\n","        color_mode = image_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = image_save_prefix,\n","        class_mode=None,\n","        seed = seed)\n","    mask_generator = mask_datagen.flow_from_directory(\n","        train_path,\n","        classes = [mask_folder],\n","        color_mode = mask_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = mask_save_prefix,\n","        class_mode=None,\n","        seed = seed)\n","    train_generator = zip(image_generator, mask_generator)\n","    for (img,mask) in train_generator:\n","        yield (img,mask)\n","    \n","\n","def testGenerator(test_path,target_size = img_size,flag_multi_class = True,as_gray = True):\n","    files=sorted(os.listdir(test_path))\n","    num_image=len(files)\n","    for i in range(num_image):\n","        img = io.imread(os.path.join(test_path,files[i]),as_gray = True)\n","        print(files[i])\n","        img = trans.resize(img,target_size)\n","        #img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n","        img = np.reshape(img,(1,)+img.shape)\n","        yield img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E0ykPbkYkuir"},"source":["#Step 4: Define function to save the test images\n","### draw imgs in labelVisualize and save results in saveResult\n","def saveResult(img_path,save_path,npyfile):\n","    files=os.listdir(img_path)\n","        \n","    for i,item in enumerate(npyfile):\n","        img=item\n","        for k in range(3):\n","            img[:,:,k]=img[:,:,k]/np.ptp(img[:,:,k])\n","            \n","        img[:,:,1]=(img[:,:,1]>0.5).astype(int) #This threshold of 0.05 can be changed to any number in range [0,1]\n","        img[:,:,0]=(img[:,:,0]>0.5).astype(int)\n","              \n","        io.imsave(os.path.join(save_path, files[i]),img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6_R2XCFukuis"},"source":["def SaveResultwImage(img_path,save_path,npyfile,target_size=img_size,flag_multi_class = True,num_class = 2):\n","    files=os.listdir(img_path)\n","    \n","    \n","    for i,item in enumerate(npyfile):\n","        img=item\n","        img[img>0.5]=1\n","        img[img<=0.5]=0\n","        img[:,:,2]=0\n","        \n","        I = io.imread(os.path.join(img_path,files[i]), as_gray=True)\n","        I = trans.resize(I,target_size)\n","        img[:,:,0]=np.true_divide((I+img[:,:,0]),2)\n","        img[:,:,1]=np.true_divide((I+img[:,:,1]),2)\n","        img[:,:,2]=np.true_divide((I+img[:,:,2]),2)\n","        io.imsave(os.path.join(save_path, files[i]),img)        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OpRBa_aWkuis"},"source":["#Step 5: Define functions to evaluate the output\n","import sklearn.metrics as sm\n","\n","def get_confusion_matrix_elements(groundtruth_list, predicted_list):\n","    \"\"\"returns confusion matrix elements i.e TN, FP, FN, TP as floats\n","\tSee example code for helper function definitions\n","    \"\"\"\n","    tn, fp, fn, tp = sm.confusion_matrix(groundtruth_list, predicted_list,labels=[0,1]).ravel()\n","    tn, fp, fn, tp = np.float64(tn), np.float64(fp), np.float64(fn), np.float64(tp)\n","\n","    return tn, fp, fn, tp\n","\n","def get_prec_rec_IoU_accuracy(groundtruth_list, predicted_list):\n","    \"\"\"returns precision, recall, IoU and accuracy metrics\n","\t\"\"\"\n","    tn, fp, fn, tp = get_confusion_matrix_elements(groundtruth_list, predicted_list)\n","    \n","    total = tp + fp + fn + tn\n","    accuracy = (tp + tn) / total\n","    prec=tp/(tp+fp)\n","    rec=tp/(tp+fn)\n","    IoU=tp/(tp+fp+fn)\n","    \n","    return prec,rec,IoU,accuracy\n","\n","def get_f1_score(groundtruth_list, predicted_list):\n","    \"\"\"Return f1 score covering edge cases\"\"\"\n","\n","    tn, fp, fn, tp = get_confusion_matrix_elements(groundtruth_list, predicted_list)\n","    \n","    f1_score = (2 * tp) / ((2 * tp) + fp + fn)\n","\n","    return f1_score\n","\n","def get_validation_metrics(groundtruth,predicted):\n","    \"\"\"Return all output metrics. Input is binary images\"\"\"\n","   \n","    u,v=np.shape(groundtruth)\n","    groundtruth_list=np.reshape(groundtruth,(u*v,))\n","    predicted_list=np.reshape(predicted,(u*v,))\n","    prec,rec,IoU,acc=get_prec_rec_IoU_accuracy(groundtruth_list, predicted_list)\n","    f1_score=get_f1_score(groundtruth_list, predicted_list)\n","   # print(\"Precision=\",prec, \"Recall=\",rec, \"IoU=\",IoU, \"acc=\",acc, \"F1=\",f1_score)\n","    return prec,rec,IoU,acc,f1_score\n","\n","def evalResult(gth_path,npyfile,target_size=img_size,flag_multi_class = False,num_class = 3):\n","    files=sorted(os.listdir(gth_path))\n","    print(files)\n","    prec=0\n","    rec=0\n","    acc=0\n","    IoU=0\n","    f1_score=0\n","    for i,item in enumerate(npyfile):\n","        img = item[:,:,0]\n","        gth = io.imread(os.path.join(gth_path,files[i]))\n","        gth = trans.resize(gth,target_size)\n","        img1=np.array(((img - np.min(img))/np.ptp(img))>0.1).astype(float)\n","        gth1=np.array(((gth - np.min(gth))/np.ptp(gth))>0.1).astype(float)\n","        p,r,I,a,f=get_validation_metrics(gth1,img1)\n","        prec=prec+p\n","        rec=rec+r\n","        acc=acc+a\n","        IoU=IoU+I\n","        f1_score=f1_score+f\n","    print(\"Precision=\",prec/(i+1), \"Recall=\",rec/(i+1), \"IoU=\",IoU/(i+1), \"acc=\",acc/(i+1), \"F1=\",f1_score/(i+1))    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"036WjKyjkuit"},"source":["# All definitions are now done! Lets start using the functions now...\n","# B. Call to image data generator, model initialization, followed by model fitting."]},{"cell_type":"code","metadata":{"id":"mfzRaSRqkuit"},"source":["#Step 1: Call to image data generator in keras\n","\n","os.chdir('/content/drive/MyDrive/U-net Multi-class/diaretdb1_v_1_1/resources/')\n","data_gen_args = dict(rotation_range=0.3,\n","                     rescale=1./255,\n","                    width_shift_range=0.2,\n","                    height_shift_range=0.2,\n","                    shear_range=0.1,\n","                    zoom_range=[0.7,1],\n","                    horizontal_flip=True,\n","                    vertical_flip=True,\n","                    fill_mode='nearest')\n","PATH='./train/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PebFECN7kuiu"},"source":["if not os.path.exists(PATH+'aug'):\n","    os.makedirs(PATH+'aug')\n","    \n","if not os.path.exists(PATH+'pred'):\n","    os.makedirs(PATH+'pred')    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wVuo91-zkuiu"},"source":["data_gen = trainGenerator(3,PATH,'images','GT',data_gen_args, save_to_dir = None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iaKBXrQykuiu"},"source":["for e in range(5):\n","    print('Epoch', e)\n","    batches = 0\n","    for x_batch, y_batch in data_gen:\n","        print(np.max(x_batch))\n","        for i in range(0, 2):\n","            plt.subplot(330+1 + i)\n","            plt.imshow(y_batch[i], cmap=plt.get_cmap('gray'))\n","        \n","\n","        plt.show()\n","        \n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKM5tKtWkuiv"},"source":["#Step 2: Initialize the model. Train from scratch!\n","model = unet()\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0FBNXhCOkuiv"},"source":["#Step 3: Initialize Tensorboard to monitor changes in Model Loss \n","import datetime\n","%load_ext tensorboard\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"vQYuJXXOkuiw"},"source":["#Visualize on tensorboard (move this above)\n","%tensorboard --logdir logs/fit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"QRcEH7kdkuiw"},"source":["#Step 4: Fit the u-net model\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint('unet_DB1_multi.hdf5', monitor='loss',verbose=0)\n","model.fit(data_gen,steps_per_epoch=20,epochs=30,verbose=1, callbacks=[model_checkpoint, tensorboard_callback])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bPQAhlUYkuiw"},"source":["# Final trained model is saved as unet_DB1.hdf5\n","# C. Run the trained model on test images and save the outputs, and evaluate pixel-level segmentation performance "]},{"cell_type":"code","metadata":{"scrolled":true,"id":"M0U1YHs_kuix"},"source":["#Step 1: Run model on test images and save the images\n","#number of test images\n","n_i=len(os.listdir('./test/images/'))\n","#Call test generator\n","test_gen = testGenerator('./test/images/')\n","#Return model outcome for each test image\n","results = model.predict_generator(test_gen,n_i,verbose=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l8A2E6Npkuix"},"source":["if not os.path.exists('./test/pred'):\n","    os.makedirs('./test/pred/')\n","\n","SaveResultwImage('./test',PATH+'pred/',results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hAOlU7Rjkuix"},"source":["print(np.sum(results))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g9Ww4As1kuiy"},"source":["plt.imshow(results[0][:,:,1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I18t61Tpkuiy"},"source":["plt.imshow(results[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hVBSXxCqkuiy"},"source":["\n","\n","\n","\n"],"execution_count":null,"outputs":[]}]}